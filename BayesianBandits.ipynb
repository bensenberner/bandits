{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian bandits\n",
    "\n",
    "Notebook describing our efforts on a Bayesian approach to bandits\n",
    "## Set-up\n",
    "\n",
    "1. Create this notebook via Jupyter in ~/Columbia/academic/src/bayesianBandits\n",
    "2. Create GitHub public (empty) repository\n",
    "3. Create local Git repository:\n",
    "    * \\$ git init\n",
    "    * \\$ add BayesianBandits.ipynb \n",
    "    * \\$ touch BayesianBandits.py\n",
    "    * \\$ git add BayesianBandits.py\n",
    "    * \\$ git commit\n",
    "    * \\$ git remote add origin https://github.com/iurteaga/BayesianBandits\n",
    "    * \\$ git push -u origin master\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian bandits simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General simulation set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from BayesianBandits import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Number of realizations\n",
    "R=pow(10,3)\n",
    "# Time instants to run\n",
    "t_max=pow(10,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different methodologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Bandit\n",
    "K=3\n",
    "reward_function=stats.bernoulli\n",
    "theta=(np.array([[0.1],[0.15],[0.2]]),)\n",
    "returns_expected=reward_function.mean(theta)\n",
    "reward_prior={'function': stats.beta, 'alpha': np.ones((3,1)), 'beta': np.ones((3,1))}\n",
    "\n",
    "# Optimal bandit\n",
    "optimal_bandit=OptimalBandit(K, reward_function, theta)\n",
    "\n",
    "# Monte Carlo bandit\n",
    "M=100\n",
    "mc_bandit=BayesianBanditMonteCarlo(K, reward_function, theta, reward_prior, M)\n",
    "# Numerical bandit\n",
    "M=100\n",
    "num_bandit=BayesianBanditNumerical(K, reward_function, theta, reward_prior, M)\n",
    "# Hybrid Monte Carlo bandit\n",
    "M=100\n",
    "hmc_bandit=BayesianBanditHybridMonteCarlo(K, reward_function, theta, reward_prior, M)\n",
    "\n",
    "# All bandits\n",
    "bandits=[optimal_bandit, num_bandit, mc_bandit, hmc_bandit]\n",
    "bandits_labels=['Optimal', 'Numerical', 'Monte Carlo', 'Hybrid Monte Carlo']\n",
    "bandits_colors=['y', 'b', 'g', 'r', 'g', 'c', 'm']\n",
    "# Execution\n",
    "bandits_returns, bandits_actions, bandits_predictive=execute_bandits(K, bandits, R, t_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plot_std=True\n",
    "t_plot=t_max\n",
    "#t_plot=25\n",
    "plot_bandits(returns_expected, bandits_returns, bandits_actions, bandits_predictive, bandits_colors, bandits_labels, t_plot, plot_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Monte Carlo sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bandit\n",
    "K=3\n",
    "reward_function=stats.bernoulli\n",
    "theta=(stats.uniform.rvs(size=K)/2,)\n",
    "returns_expected=reward_function.mean(theta)\n",
    "reward_prior={'function': stats.beta, 'alpha': np.ones((K,1)), 'beta': np.ones((K,1))}\n",
    "\n",
    "# Monte Carlo bandits\n",
    "M_samples=np.array([1, 1000])\n",
    "bandits=[]\n",
    "bandits_labels=[]\n",
    "for n in np.arange(M_samples.size):\n",
    "    bandits.append(BayesianBanditMonteCarlo(K, reward_function, theta, reward_prior, M_samples[n]))\n",
    "    bandits_labels.append('M={}'.format(M_samples[n]))\n",
    "bandits_colors=['b', 'g', 'r', 'm', 'c', 'y']\n",
    "# Execution\n",
    "bandits_returns, bandits_actions, bandits_predictive=execute_bandits(K, bandits, R, t_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(theta)\n",
    "print(returns_expected.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting All\n",
    "# With variance\n",
    "plot_std=True\n",
    "t_plot=t_max\n",
    "plot_bandits(returns_expected, bandits_returns, bandits_actions, bandits_predictive, bandits_colors, bandits_labels, t_plot, plot_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting All\n",
    "# With No variance\n",
    "plot_std=False\n",
    "t_plot=t_max\n",
    "plot_bandits(returns_expected, bandits_returns, bandits_actions, bandits_predictive, bandits_colors, bandits_labels, t_plot, plot_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting initial\n",
    "# With variance\n",
    "plot_std=True\n",
    "t_plot=100\n",
    "plot_bandits(returns_expected, bandits_returns, bandits_actions, bandits_predictive, bandits_colors, bandits_labels, t_plot, plot_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting Initial\n",
    "# With No variance\n",
    "plot_std=False\n",
    "t_plot=100\n",
    "plot_bandits(returns_expected, bandits_returns, bandits_actions, bandits_predictive, bandits_colors, bandits_labels, t_plot, plot_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
