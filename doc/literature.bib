% This file was created with JabRef 2.10.
% Encoding: ISO8859_1


@Article{j-Agrawal2012,
  Title                    = {{Thompson Sampling for Contextual Bandits with Linear Payoffs}},
  Author                   = {Shipra Agrawal and Navin Goyal},
  Journal                  = {CoRR},
  Year                     = {2012},
  Volume                   = {abs/1209.3352},

  Owner                    = {iurteaga},
  Timestamp                = {2017.05.10},
  Url                      = {http://arxiv.org/abs/1209.3352}
}

@Article{j-Agrawal2012a,
  Title                    = {{Further Optimal Regret Bounds for Thompson Sampling}},
  Author                   = {Shipra Agrawal and Navin Goyal},
  Journal                  = {CoRR},
  Year                     = {2012},
  Volume                   = {abs/1209.3353},

  Owner                    = {iurteaga},
  Timestamp                = {2017.05.10},
  Url                      = {http://arxiv.org/abs/1209.3353}
}

@Article{j-Agrawal2011,
  Title                    = {{Analysis of Thompson Sampling for the multi-armed bandit problem}},
  Author                   = {Shipra Agrawal and Navin Goyal},
  Journal                  = {CoRR},
  Year                     = {2011},
  Volume                   = {abs/1111.1797},

  Abstract                 = {The multi-armed bandit problem is a popular model for studying exploration/exploitation trade-off in sequential decision problems. Many algorithms are now available for this well-studied problem. One of the earliest algorithms, given by W. R. Thompson, dates back to 1933. This algorithm, referred to as Thompson Sampling, is a natural Bayesian algorithm. The basic idea is to choose an arm to play according to its probability of being the best arm. Thompson Sampling algorithm has experimentally been shown to be close to optimal. In addition, it is efficient to implement and exhibits several desirable properties such as small regret for delayed feedback. However, theoretical understanding of this algorithm was quite limited. In this paper, for the first time, we show that Thompson Sampling algorithm achieves logarithmic expected regret for the multi-armed bandit problem. More precisely, for the two-armed bandit problem, the expected regret in time T is O(lnTΔ+1Δ3). And, for the N-armed bandit problem, the expected regret in time T is O([(∑Ni=21Δ2i)2]lnT). Our bounds are optimal but for the dependence on Δi and the constant factors in big-Oh.},
  Keywords                 = {Thompson sampling, multi-armed bandit, bounds},
  Owner                    = {iurteaga},
  Timestamp                = {2016.10.20},
  Url                      = {http://arxiv.org/abs/1111.1797}
}

@Article{j-Auer2002,
  Title                    = {{Finite-time Analysis of the Multiarmed Bandit Problem}},
  Author                   = {Peter Auer and Nicol\`{o} Cesa-Bianchi and Paul Fischer},
  Journal                  = {Machine Learning},
  Year                     = {2002},

  Month                    = may,
  Number                   = {2-3},
  Pages                    = {235--256},
  Volume                   = {47},

  Acmid                    = {599677},
  Address                  = {Hingham, MA, USA},
  Doi                      = {10.1023/A:1013689704352},
  ISSN                     = {0885-6125},
  Issue_date               = {May-June 2002},
  Keywords                 = {adaptive allocation rules, bandit problems, finite horizon regret},
  Numpages                 = {22},
  Owner                    = {iurteaga},
  Publisher                = {Kluwer Academic Publishers},
  Timestamp                = {2017.05.10},
  Url                      = {http://dx.doi.org/10.1023/A:1013689704352}
}

@Article{j-Bellm1956,
  Title                    = {{A Problem in the Sequential Design of Experiments}},
  Author                   = {Richard Bellman},
  Journal                  = {Sankhya: The Indian Journal of Statistics (1933 - 1960)},
  Year                     = {1956},
  Number                   = {3/4},
  Pages                    = {221-229},
  Volume                   = {16},

  Owner                    = {iurteaga},
  Publisher                = {Springer},
  Timestamp                = {2017.05.10},
  Url                      = {http://www.jstor.org/stable/25048278}
}

@Book{b-Bernardo2009,
  Title                    = {{Bayesian Theory}},
  Author                   = {Jos\'{e} M. Bernardo and Adrian F.M. Smith},
  Publisher                = {Wiley},
  Year                     = {2009},
  Series                   = {Wiley Series in Probability and Statistics},

  Doi                      = {10.1002/9780470316870},
  ISBN                     = {9780470317716},
  Owner                    = {iurteaga},
  Timestamp                = {2017.05.10},
  Url                      = {http://onlinelibrary.wiley.com/book/10.1002/9780470316870}
}

@Article{j-Beygelzimer2008,
  Title                    = {{The Offset Tree for Learning with Partial Labels}},
  Author                   = {Alina Beygelzimer and John Langford},
  Journal                  = {CoRR},
  Year                     = {2008},
  Volume                   = {abs/0812.4044},

  File                     = {Tree learning with partial labels:home/iurteaga/Columbia/academic/bib/offpolicyAndCounterfactual/offsetTreeLerningPartialLabels_Beygelzimer2016.pdf:PDF},
  Owner                    = {iurteaga},
  Timestamp                = {2016.10.19},
  Url                      = {http://arxiv.org/abs/0812.4044}
}

@Book{b-Bishop2006,
  Title                    = {{Pattern Recognition and Machine Learning}},
  Author                   = {Christopher Bishop},
  Publisher                = {Springer-Verlag New York},
  Year                     = {2006},
  Series                   = {Information Science and Statistics},

  Owner                    = {iurteaga},
  Timestamp                = {2017.05.13},
  Url                      = {http://www.springer.com/us/book/9780387310732}
}

@Article{j-Blei2012,
  Title                    = {{Probabilistic Topic Models}},
  Author                   = {David M. Blei},
  Journal                  = {Commun. ACM},
  Year                     = {2012},

  Month                    = apr,
  Number                   = {4},
  Pages                    = {77--84},
  Volume                   = {55},

  Acmid                    = {2133826},
  Address                  = {New York, NY, USA},
  Doi                      = {10.1145/2133806.2133826},
  ISSN                     = {0001-0782},
  Issue_date               = {April 2012},
  Numpages                 = {8},
  Owner                    = {iurteaga},
  Publisher                = {ACM},
  Timestamp                = {2016.11.15},
  Url                      = {http://doi.acm.org/10.1145/2133806.2133826}
}

@Article{j-Blei2006a,
  Title                    = {{Variational inference for Dirichlet process mixtures}},
  Author                   = {David M. Blei and Michael I. Jordan},
  Journal                  = {Bayesian analysis},
  Year                     = {2006},
  Number                   = {1},
  Pages                    = {121--144},
  Volume                   = {1},

  Abstract                 = {Dirichlet process (DP) mixture models are the cornerstone of nonparametric Bayesian statistics, and the development of Monte-Carlo Markov chain (MCMC) sampling methods for DP mixtures has enabled the application of nonparametric Bayesian methods to a variety of practical data analysis problems. However, MCMC sampling can be prohibitively slow, and it is important to explore alternatives. One class of alternatives is provided by variational methods, a class of deterministic algorithms that convert inference problems into optimization problems (Opper and Saad 2001; Wainwright and Jordan 2003). Thus far, variational methods have mainly been explored in the parametric setting, in particular within the formalism of the exponential family (Attias 2000; Ghahramani and Beal 2001; Blei et al. 2003). In this paper, we present a variational inference algorithm for DP mixtures. We present experiments that compare the algorithm to Gibbs sampling algorithms for DP mixtures of Gaussians and present an application to a large-scale image analysis problem},
  Owner                    = {iurteaga},
  Timestamp                = {2016.11.15},
  Url                      = {http://www.cs.princeton.edu/courses/archive/fall11/cos597C/reading/BleiJordan2005.pdf}
}

@InProceedings{ip-Blei2004,
  Title                    = {{Variational Methods for the Dirichlet Process}},
  Author                   = {David M. Blei and Michael I. Jordan},
  Booktitle                = {Proceedings of the Twenty-first International Conference on Machine Learning},
  Year                     = {2004},

  Address                  = {New York, NY, USA},
  Pages                    = {12--},
  Publisher                = {ACM},
  Series                   = {ICML '04},

  Acmid                    = {1015439},
  Doi                      = {10.1145/1015330.1015439},
  ISBN                     = {1-58113-838-5},
  Location                 = {Banff, Alberta, Canada},
  Owner                    = {iurteaga},
  Timestamp                = {2016.11.15},
  Url                      = {http://doi.acm.org/10.1145/1015330.1015439}
}

@InProceedings{ip-Blei2006,
  Title                    = {{Dynamic topic models}},
  Author                   = {David M. Blei and John D. Lafferty},
  Booktitle                = {Proceedings of the 23rd international conference on Machine learning},
  Year                     = {2006},
  Organization             = {ACM},
  Pages                    = {113--120},

  Abstract                 = {A family of probabilistic time series models is developed to analyze the time evolution of topics in large document collections. The approach is to use state space models on the natural parameters of the multinomial distributions that represent the topics. Variational approximations based on Kalman filters and nonparametric wavelet regression are developed to carry out approximate posterior inference over the latent topics. In addition to giving quantitative, predictive models of a sequential corpus, dynamic topic models provide a qualitative window into the contents of a large document collection. The models are demonstrated by analyzing the OCR’ed archives of the journal Science from 1880 through 2000.},
  Owner                    = {iurteaga},
  Timestamp                = {2016.11.15},
  Url                      = {https://mimno.infosci.cornell.edu/info6150/readings/dynamic_topic_models.pdf}
}

@Article{j-Blei2006,
  Title                    = {{Correlated topic models}},
  Author                   = {David M. Blei and John D. Lafferty},
  Journal                  = {Advances in neural information processing systems},
  Year                     = {2006},
  Pages                    = {147},
  Volume                   = {18},

  Owner                    = {iurteaga},
  Publisher                = {MIT; 1998},
  Timestamp                = {2016.11.15},
  Url                      = {http://galton.uchicago.edu/~lafferty/pdf/ctm.pdf}
}

@Article{j-Blei2003,
  Title                    = {{Latent Dirichlet allocation}},
  Author                   = {Blei, David M and Ng, Andrew Y and Jordan, Michael I},
  Journal                  = {Journal of machine Learning research},
  Year                     = {2003},
  Number                   = {Jan},
  Pages                    = {993--1022},
  Volume                   = {3},

  Abstract                 = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
  Owner                    = {iurteaga},
  Timestamp                = {2016.11.15},
  Url                      = {http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf}
}

@Article{j-Bottou2012,
  Title                    = {{Counterfactual Reasoning and Learning Systems}},
  Author                   = {L{\'{e}}on Bottou and Jonas Peters and Joaquin Qui{\~{n}}onero Candela and Denis Xavier Charles and Max Chickering and Elon Portugaly and Dipankar Ray and Patrice Y. Simard and Ed Snelson},
  Journal                  = {CoRR},
  Year                     = {2012},
  Volume                   = {abs/1209.2355},

  File                     = {Counterfactual reasoning and learning:home/iurteaga/Columbia/academic/bib/offpolicyAndCounterfactual/counterfactualResonaingAndLearning_Bottou2013.pdf:PDF},
  Owner                    = {iurteaga},
  Timestamp                = {2016.10.19},
  Url                      = {http://arxiv.org/abs/1209.2355}
}

@Article{j-Brezzi2002,
  Title                    = {{Optimal learning and experimentation in bandit problems}},
  Author                   = {Monica Brezzi and Tze Leung Lai},
  Journal                  = {Journal of Economic Dynamics and Control},
  Year                     = {2002},
  Number                   = {1},
  Pages                    = {87 - 108},
  Volume                   = {27},

  Doi                      = {https://doi.org/10.1016/S0165-1889(01)00028-8},
  ISSN                     = {0165-1889},
  Owner                    = {iurteaga},
  Timestamp                = {2017.05.10},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0165188901000288}
}

@Article{j-Brezzi2000,
  Title                    = {{Incomplete Learning from Endogenous Data in Dynamic Allocation}},
  Author                   = {Monica Brezzi and Tze Leung Lai},
  Journal                  = {Econometrica},
  Year                     = {2000},
  Number                   = {6},
  Pages                    = {1511--1516},
  Volume                   = {68},

  Doi                      = {10.1111/1468-0262.00170},
  ISSN                     = {1468 0262},
  Owner                    = {iurteaga},
  Publisher                = {Blackwell Publishers Ltd},
  Timestamp                = {2017.05.10},
  Url                      = {http://dx.doi.org/10.1111/1468-0262.00170}
}

@InProceedings{ip-Chang2009,
  Title                    = {{Reading Tea Leaves: How Humans Interpret Topic Models}},
  Author                   = {Jonathan Chang and Jordan Boyd-Graber and Chong Wang and Sean Gerrish and David M. Blei},
  Booktitle                = {Neural Information Processing Systems},
  Year                     = {2009},

  Keywords                 = {Topic models, interpretation, held-out likelihood},
  Location                 = {Vancouver, BC},
  Owner                    = {iurteaga},
  Timestamp                = {2017.04.20},
  Url                      = {https://www.umiacs.umd.edu/~jbg/docs/nips2009-rtl.pdf}
}

@InCollection{ic-Chapelle2011,
  Title                    = {{An Empirical Evaluation of Thompson Sampling}},
  Author                   = {Olivier Chapelle and Lihong Li},
  Booktitle                = {Advances in Neural Information Processing Systems 24},
  Publisher                = {Curran Associates, Inc.},
  Year                     = {2011},
  Editor                   = {J. Shawe-Taylor and R. S. Zemel and P. L. Bartlett and F. Pereira and K. Q. Weinberger},
  Pages                    = {2249--2257},

  File                     = {:home/iurteaga/Columbia/academic/bib/causalModelingAndBandits/4321-an-empirical-evaluation-of-thompson-sampling_Chapelle2011.pdf:PDF},
  Owner                    = {iurteaga},
  Timestamp                = {2016.09.19},
  Url                      = {http://papers.nips.cc/paper/4321-an-empirical-evaluation-of-thompson-sampling.pdf}
}

@Article{j-Dempster1977,
  Title                    = {{Maximum likelihood from incomplete data via the EM algorithm}},
  Author                   = {Arthur P. Dempster and Nan M. Laird and Donald B. Rubin},
  Journal                  = {Journal of the royal statistical society. Series B (methodological)},
  Year                     = {1977},
  Pages                    = {1--38},

  Owner                    = {iurteaga},
  Publisher                = {Royal Statistical Society},
  Timestamp                = {2017.05.19},
  Url                      = {https://www.jstor.org/stable/2984875}
}

@Article{j-Ghavamzadeh2015,
  Title                    = {{Bayesian Reinforcement Learning: A Survey}},
  Author                   = {Mohammad Ghavamzadeh and Shie Mannor and Joelle Pineau and Aviv Tamar},
  Journal                  = {Foundations and Trends® in Machine Learning},
  Year                     = {2015},
  Number                   = {5-6},
  Pages                    = {359-483},
  Volume                   = {8},

  Abstract                 = {Bayesian methods for machine learning have been widely investigated, yielding principled methods for incorporating prior information into inference algorithms. In this survey, we provide an in-depth review of the role of Bayesian methods for the reinforcement learning (RL) paradigm. The major incentives for incorporating Bayesian reasoning in RL are: 1) it provides an elegant approach to action-selection (exploration/ exploitation) as a function of the uncertainty in learning; and 2) it provides a machinery to incorporate prior knowledge into the algorithms. We first discuss models and methods for Bayesian inference in the simple single-step Bandit model. We then review the extensive recent literature on Bayesian methods for model-based RL, where prior information can be expressed on the parameters of the Markov model. We also present Bayesian methods for model-free RL, where priors are expressed over the value function or policy class. The objective of the paper is to provide a comprehensive survey on Bayesian RL algorithms and their theoretical and empirical properties.},
  Doi                      = {10.1561/2200000049},
  File                     = {Survey of Bayesian Reinforcement Learning:home/iurteaga/Columbia/academic/bib/reinforcementLearning/bayesianReinforcementLearning_Ghavamzadeh2016.pdf:PDF},
  ISSN                     = {1935-8237},
  Keywords                 = {Reinforcement Learning, Bayesian},
  Owner                    = {iurteaga},
  Timestamp                = {2016.10.19},
  Url                      = {http://dx.doi.org/10.1561/2200000049}
}

@Article{j-Gittins1979,
  Title                    = {{Bandit Processes and Dynamic Allocation Indices}},
  Author                   = {J. C. Gittins},
  Journal                  = {Journal of the Royal Statistical Society. Series B (Methodological)},
  Year                     = {1979},
  Number                   = {2},
  Pages                    = {148-177},
  Volume                   = {41},

  Abstract                 = {The paper aims to give a unified account of the central concepts in recent work on bandit processes and dynamic allocation indices; to show how these reduce some previously intractable problems to the problem of calculating such indices; and to describe how these calculations may be carried out. Applications to stochastic scheduling, sequential clinical trials and a class of search problems are discussed.},
  File                     = {Gittins and Bandit processes:home/iurteaga/Columbia/academic/bib/causalModelingAndBandits/banditProcessesAndDynamicaAllocationIndices_Gittins1979.pdf:PDF},
  ISSN                     = {00359246},
  Owner                    = {iurteaga},
  Publisher                = {[Royal Statistical Society, Wiley]},
  Timestamp                = {2016.09.20},
  Url                      = {http://www.jstor.org/stable/2985029}
}

@Article{j-Hoffman2013,
  Title                    = {{Stochastic variational inference}},
  Author                   = {Matthew D. Hoffman and David M. Blei and Chong Wang and John William Paisley},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2013},

  Abstract                 = {We develop stochastic variational inference, a scalable algorithm for approximating posterior distributions.
We develop this technique for a large class of probabilistic models and we demonstrate
it with two probabilistic topic models, latent Dirichlet allocation and the hierarchical Dirichlet process
topic model. Using stochastic variational inference, we analyze several large collections of
documents: 300K articles from Nature, 1.8M articles from The New York Times, and 3.8M articles
from Wikipedia. Stochastic inference can easily handle data sets of this size and outperforms
traditional variational inference, which can only handle a smaller subset. (We also show that the
Bayesian nonparametric topic model outperforms its parametric counterpart.) Stochastic variational
inference lets us apply complex Bayesian models to massive data sets.},
  Keywords                 = {Bayesian inference, variational inference, stochastic optimization, topic models, Bayesian nonparametrics},
  Owner                    = {iurteaga},
  Timestamp                = {2016.11.15},
  Url                      = {http://www.jmlr.org/papers/volume14/hoffman13a/hoffman13a.pdf}
}

@Misc{Kearns1999,
  Title                    = {{Approximate Planning in Large POMDPs via Reusable Trajectories }},

  Author                   = {Michael Kearns and Yishay Mansour and Andrew Y. Ng},
  Year                     = {1999},

  File                     = {Off policy learning, Markov decision process:home/iurteaga/Columbia/academic/bib/offpolicyAndCounterfactual/approxPlanningTrajectories_Kearns1999.pdf:PDF},
  Owner                    = {iurteaga},
  Timestamp                = {2016.10.19},
  Url                      = {http://www.andrewng.org/portfolio/approximate-planning-in-large-pomdps-via-reusable-trajectories/}
}

@InCollection{ic-Korda2013,
  Title                    = {{Thompson Sampling for 1-Dimensional Exponential Family Bandits}},
  Author                   = {Nathaniel Korda and Emilie Kaufmann and R{\'e}mi Munos},
  Booktitle                = {Advances in Neural Information Processing Systems 26},
  Publisher                = {Curran Associates, Inc.},
  Year                     = {2013},
  Editor                   = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
  Pages                    = {1448--1456},

  Owner                    = {iurteaga},
  Timestamp                = {2017.05.19},
  Url                      = {http://papers.nips.cc/paper/5110-thompson-sampling-for-1-dimensional-exponential-family-bandits.pdf}
}

@Article{j-Lai1987,
  Title                    = {{Adaptive Treatment Allocation and the Multi-Armed Bandit Problem}},
  Author                   = {Tze Leung Lai},
  Journal                  = {The Annals of Statistics},
  Year                     = {1987},
  Number                   = {3},
  Pages                    = {1091-1114},
  Volume                   = {15},

  ISSN                     = {00905364},
  Owner                    = {iurteaga},
  Publisher                = {Institute of Mathematical Statistics},
  Timestamp                = {2017.05.10},
  Url                      = {http://www.jstor.org/stable/2241818}
}

@Article{j-Lai1985,
  Title                    = {{Asymptotically Efficient Adaptive Allocation Rules}},
  Author                   = {Tze Leung Lai and Herbert Robbins},
  Journal                  = {Advances in Applied Mathematics},
  Year                     = {1985},

  Month                    = {mar},
  Number                   = {1},
  Pages                    = {4--22},
  Volume                   = {6},

  Acmid                    = {2609757},
  Address                  = {Orlando, FL, USA},
  Doi                      = {10.1016/0196-8858(85)90002-8},
  ISSN                     = {0196-8858},
  Issue_date               = {March, 1985},
  Numpages                 = {19},
  Owner                    = {iurteaga},
  Publisher                = {Academic Press, Inc.},
  Timestamp                = {2017.05.10},
  Url                      = {http://dx.doi.org/10.1016/0196-8858(85)90002-8}
}

@InProceedings{ip-Langford2005,
  Title                    = {{Relating Reinforcement Learning Performance to Classification Performance}},
  Author                   = {John Langford and Bianca Zadrozny},
  Booktitle                = {Proceedings of the 22Nd International Conference on Machine Learning},
  Year                     = {2005},

  Address                  = {New York, NY, USA},
  Pages                    = {473--480},
  Publisher                = {ACM},
  Series                   = {ICML '05},

  Acmid                    = {1102411},
  Doi                      = {10.1145/1102351.1102411},
  File                     = {Reinforcement kearning and classification:home/iurteaga/Columbia/academic/bib/offpolicyAndCounterfactual/reinforcementToClassificationPerformance_langford2005.ps:PostScript},
  ISBN                     = {1-59593-180-5},
  Location                 = {Bonn, Germany},
  Numpages                 = {8},
  Owner                    = {iurteaga},
  Timestamp                = {2016.10.19},
  Url                      = {http://doi.acm.org/10.1145/1102351.1102411}
}

@Article{j-Li2013,
  Title                    = {{Generalized Thompson Sampling for Contextual Bandits}},
  Author                   = {Lihong Li},
  Journal                  = {ArXiv e-prints},
  Year                     = {2013},

  Month                    = oct,

  Adsurl                   = {http://adsabs.harvard.edu/abs/2013arXiv1310.7163L},
  Archiveprefix            = {arXiv},
  Eprint                   = {1310.7163},
  File                     = {Generalized Thompson sampling:home/iurteaga/Columbia/academic/bib/causalModelingAndBandits/generalizedThompsonSamplingContextualBandits_Li2013.pdf:PDF},
  Keywords                 = {Computer Science - Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning, Statistics - Other Statistics, 62L05, I.2.6},
  Owner                    = {iurteaga},
  Primaryclass             = {cs.LG},
  Timestamp                = {2016.09.19},
  Url                      = {https://arxiv.org/abs/1310.7163}
}

@Article{j-Li2010,
  Title                    = {{A Contextual-Bandit Approach to Personalized News Article Recommendation}},
  Author                   = {Lihong Li and Wei Chu and John Langford and Robert E. Schapire},
  Journal                  = {CoRR},
  Year                     = {2010},
  Volume                   = {abs/1003.0146},

  Bibsource                = {dblp computer science bibliography, http://dblp.org},
  Biburl                   = {http://dblp.uni-trier.de/rec/bib/journals/corr/abs-1003-0146},
  Owner                    = {iurteaga},
  Timestamp                = {2017.04.04},
  Url                      = {http://arxiv.org/abs/1003.0146}
}

@InProceedings{ip-Maillard2011,
  Title                    = {{Finite-Time Analysis of Multi-armed Bandits Problems with Kullback-Leibler Divergences}},
  Author                   = {Odalric-Ambrym Maillard and R{\'e}mi Munos and Gilles Stoltz},
  Booktitle                = {Conference On Learning Theory},
  Year                     = {2011},

  Abstract                 = {We consider a Kullback-Leibler-based algorithm for the stochastic multi-armed bandit problem in the case of distributions with finite supports (not necessarily known beforehand), whose asymptotic regret matches the lower bound of Burnetas and Katehakis (1996). Our contribution is to provide a finite-time analysis of this algorithm; we get bounds whose main terms are smaller than the ones of previously known algorithms with finite-time analyses (like UCB-type algorithms)},
  Owner                    = {iurteaga},
  Timestamp                = {2017.05.19},
  Url                      = {http://hal.inria.fr/inria-00574987/fr/}
}

@Book{b-McLachlan2004,
  Title                    = {{Finite Mixture Models}},
  Author                   = {Geoffrey McLachlan and David Peel},
  Publisher                = {John Wiley \& Sons, 2004},
  Year                     = {2004},
  Series                   = {Wiley Series in Probability and Statistics},

  ISBN                     = {9780471654063},
  Owner                    = {iurteaga},
  Timestamp                = {2017.05.12},
  Url                      = {https://books.google.cz/books?id=c2\_fAox0DQoC}
}

@Article{j-Ortega2010,
  Title                    = {{A Minimum Relative Entropy Principle for Learning and Acting}},
  Author                   = {Pedro A. Ortega and Daniel A. Braun},
  Journal                  = {Journal of Artificial Intelligence Research},
  Year                     = {2010},

  Month                    = may,
  Number                   = {1},
  Pages                    = {475--511},
  Volume                   = {38},

  Acmid                    = {1892223},
  Address                  = {USA},
  File                     = {:home/iurteaga/Columbia/academic/bib/causalModelingAndBandits/entropyLearningActing_Ortega2010.pdf:PDF},
  ISSN                     = {1076-9757},
  Issue_date               = {May 2010},
  Numpages                 = {37},
  Owner                    = {iurteaga},
  Publisher                = {AI Access Foundation},
  Timestamp                = {2016.09.19},
  Url                      = {http://dl.acm.org/citation.cfm?id=1892211.1892223}
}

@Article{j-Pearl2009,
  Title                    = {{Causal inference in statistics: An overview}},
  Author                   = {Judea Pearl},
  Journal                  = {Statist. Surv.},
  Year                     = {2009},
  Pages                    = {96--146},
  Volume                   = {3},

  Doi                      = {10.1214/09-SS057},
  File                     = {Causal inference in statistics by Judea Pearl:home/iurteaga/Columbia/academic/bib/causalModelingAndBandits/causalInferenceInStatistics_Pearl2009.pdf:PDF},
  Fjournal                 = {Statistics Surveys},
  Owner                    = {iurteaga},
  Publisher                = {The American Statistical Association, the Bernoulli Society, the Institute of Mathematical Statistics, and the Statistical Society of Canada},
  Timestamp                = {2016.09.14},
  Url                      = {http://dx.doi.org/10.1214/09-SS057}
}

@Article{j-Pivovarov2015,
  Title                    = {{Learning probabilistic phenotypes from heterogeneous \{EHR\} data}},
  Author                   = {Rimma Pivovarov and Adler J. Perotte and Edouard Grave and John Angiolillo and Chris H. Wiggins and Noémie Elhadad},
  Journal                  = {Journal of Biomedical Informatics},
  Year                     = {2015},
  Pages                    = {156 - 165},
  Volume                   = {58},

  Abstract                 = {Abstract We present the Unsupervised Phenome Model (UPhenome), a probabilistic graphical model for large-scale discovery of computational models of disease, or phenotypes. We tackle this challenge through the joint modeling of a large set of diseases and a large set of clinical observations. The observations are drawn directly from heterogeneous patient record data (notes, laboratory tests, medications, and diagnosis codes), and the diseases are modeled in an unsupervised fashion. We apply \{UPhenome\} to two qualitatively different mixtures of patients and diseases: records of extremely sick patients in the intensive care unit with constant monitoring, and records of outpatients regularly followed by care providers over multiple years. We demonstrate that the \{UPhenome\} model can learn from these different care settings, without any additional adaptation. Our experiments show that (i) the learned phenotypes combine the heterogeneous data types more coherently than baseline LDA-based phenotypes; (ii) they each represent single diseases rather than a mix of diseases more often than the baseline ones; and (iii) when applied to unseen patient records, they are correlated with the patients’ ground-truth disorders. Code for training, inference, and quantitative evaluation is made available to the research community. },
  Doi                      = {http://dx.doi.org/10.1016/j.jbi.2015.10.001},
  ISSN                     = {1532-0464},
  Keywords                 = {Probabilistic modeling, Computational disease models, Phenotyping, Clinical phenotype modeling, Medical information systems, Electronic health record },
  Owner                    = {iurteaga},
  Timestamp                = {2016.11.15},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1532046415002233}
}

@Article{j-Robbins1956,
  Title                    = {{A sequential decision procedure with a finite memory}},
  Author                   = {Herbert Robbins},
  Journal                  = {Proceedings of the National Academy of Science},
  Year                     = {1956},
  Number                   = {42},
  Pages                    = {920 - 923},

  Owner                    = {iurteaga},
  Timestamp                = {2017.05.10}
}

@Article{j-Robbins1952,
  Title                    = {{Some aspects of the sequential design of experiments}},
  Author                   = {Herbert Robbins},
  Journal                  = {Bulletin of the American Mathematical Society},
  Year                     = {1952},
  Number                   = {58},
  Pages                    = {527-535},

  Doi                      = {https://doi.org/10.1090/S0002-9904-1952-09620-8},
  Owner                    = {iurteaga},
  Timestamp                = {2017.05.10}
}

@Article{j-Russo2016,
  Title                    = {{An information-theoretic analysis of Thompson sampling}},
  Author                   = {Daniel Russo and Benjamin Van Roy},
  Journal                  = {The Journal of Machine Learning Research},
  Year                     = {2016},
  Number                   = {1},
  Pages                    = {2442--2471},
  Volume                   = {17},

  Keywords                 = {Online optimization; Multi-armed bandits; Thompson sampling; Information theory; Regret bounds;},
  Owner                    = {iurteaga},
  Publisher                = {JMLR. org},
  Timestamp                = {2017.08.02},
  Url                      = {http://www.jmlr.org/papers/volume17/14-087/14-087.pdf}
}

@Article{j-Russo2014,
  Title                    = {{Learning to optimize via posterior sampling}},
  Author                   = {Daniel Russo and Benjamin Van Roy},
  Journal                  = {Mathematics of Operations Research},
  Year                     = {2014},
  Number                   = {4},
  Pages                    = {1221--1243},
  Volume                   = {39},

  Doi                      = {http://pubsonline.informs.org/doi/abs/10.1287/moor.2014.0650},
  Keywords                 = {Online optimization; Multi-armed bandits; Thompson sampling; theoretical bounds;},
  Owner                    = {iurteaga},
  Timestamp                = {2017.08.02}
}

@Article{j-Scott2015,
  Title                    = {{Multi-armed bandit experiments in the online service economy}},
  Author                   = {Steven L. Scott},
  Journal                  = {Applied Stochastic Models in Business and Industry},
  Year                     = {2015},
  Note                     = {Special issue on actual impact and future perspectives on stochastic modelling in business and industry},
  Pages                    = {37--49},
  Volume                   = {31},

  Abstract                 = {The modern service economy is substantively different from the agricultural and manufacturing economies that preceded it. In particular, the cost of experimenting is dominated by opportunity cost rather than the cost of obtaining experimental units. The different economics require a new class of experiments, in which stochastic models play an important role. This article briefly summarizes mulit-armed bandit experiments, where the experimental design is modified as the experiment progresses to make the experiment as inexpensive as possible.},
  Owner                    = {iurteaga},
  Timestamp                = {2017.04.04},
  Url                      = {http://onlinelibrary.wiley.com/doi/10.1002/asmb.2104/abstract}
}

@Article{j-Scott2010,
  Title                    = {{A modern Bayesian look at the multi-armed bandit}},
  Author                   = {Steven L. Scott},
  Journal                  = {Applied Stochastic Models in Business and Industry},
  Year                     = {2010},
  Number                   = {6},
  Pages                    = {639--658},
  Volume                   = {26},

  Doi                      = {10.1002/asmb.874},
  File                     = {Bayesian approach to Multi Armed Bandit problem:home/iurteaga/Columbia/academic/bib/causalModelingAndBandits/bayesianMultiArmedBandit_Scott2010.pdf:PDF},
  ISSN                     = {1526-4025},
  Keywords                 = {probability matching, exploration vs exploitation, sequential design, Bayesian adaptive design},
  Owner                    = {iurteaga},
  Publisher                = {John Wiley \& Sons, Ltd.},
  Timestamp                = {2016.09.19},
  Url                      = {http://dx.doi.org/10.1002/asmb.874}
}

@Article{j-Shahriari2016,
  Title                    = {{Taking the Human Out of the Loop: A Review of Bayesian Optimization}},
  Author                   = {Bobak Shahriari and Kevin Swersky and Ziyu Wang and Ryan P. Adams and Nando de Freitas},
  Journal                  = {Proceedings of the IEEE},
  Year                     = {2016},

  Month                    = {Jan},
  Number                   = {1},
  Pages                    = {148-175},
  Volume                   = {104},

  Abstract                 = {Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., recommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involve many tunable configuration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.},
  Doi                      = {10.1109/JPROC.2015.2494218},
  File                     = {Review of Bayesian optimization:home/iurteaga/Columbia/academic/bib/bayesianOptimization_Shahriari2016.pdf:PDF},
  ISSN                     = {0018-9219},
  Keywords                 = {Bayes methods;Big Data;optimisation;storage allocation;Bayesian optimization;Big data application;human productivity;large-scale heterogeneous computing;massive complex software system;product quality;storage architecture;Bayes methods;Big data;Decision making;Design of experiments;Genomes;Linear programming;Optimization;Statistical analysis;Decision making;decision making;design of experiments;genomic medicine;optimization;response surface methodology;statistical learning},
  Owner                    = {iurteaga},
  Timestamp                = {2016.10.19}
}

@Article{j-Strehl2010,
  Title                    = {{Learning from Logged Implicit Exploration Data}},
  Author                   = {Alexander L. Strehl and John Langford and Sham M. Kakade},
  Journal                  = {CoRR},
  Year                     = {2010},
  Volume                   = {abs/1003.0120},

  File                     = {Policy evaluation, exploration data:home/iurteaga/Columbia/academic/bib/offpolicyAndCounterfactual/3977-learning-from-logged-implicit-exploration-data.pdf:PDF},
  Owner                    = {iurteaga},
  Timestamp                = {2016.10.19},
  Url                      = {http://arxiv.org/abs/1003.0120}
}

@InProceedings{ip-Strehl2010,
  Title                    = {{Learning from Logged Implicit Exploration Data}},
  Author                   = {Alexander L. Strehl and John Langford and Lihong Li and Sham Kakade},
  Booktitle                = {Advances in Neural Information Processing Systems 23: 24th Annual Conference on Neural Information Processing Systems 2010. Proceedings of a meeting held 6-9 December 2010, Vancouver, British Columbia,
 Canada.},
  Year                     = {2010},
  Pages                    = {2217--2225},

  Biburl                   = {http://dblp.uni-trier.de/rec/bib/conf/nips/StrehlLLK10},
  File                     = {:home/iurteaga/Columbia/academic/bib/causalModelingAndBandits/3977-learning-from-logged-implicit-exploration-data.pdf:PDF},
  Owner                    = {iurteaga},
  Timestamp                = {2016.10.19},
  Url                      = {http://papers.nips.cc/paper/3977-learning-from-logged-implicit-exploration-data}
}

@Book{b-Sutton1998,
  Title                    = {{Reinforcement Learning: An Introduction}},
  Author                   = {Richard S. Sutton and Andrew G. Barto},
  Publisher                = {MIT Press: Cambridge, MA},
  Year                     = {1998},

  Owner                    = {iurteaga},
  Timestamp                = {2017.05.10},
  Url                      = {https://mitpress.mit.edu/books/reinforcement-learning}
}

@Article{j-Teh2006,
  Title                    = {{Hierarchical Dirichlet Processes}},
  Author                   = {Yee Whye Teh and Michael I Jordan and Matthew J Beal and David M Blei},
  Journal                  = {Journal of the American Statistical Association},
  Year                     = {2006},
  Number                   = {476},
  Pages                    = {1566-1581},
  Volume                   = {101},

  Abstract                 = {We consider problems involving groups of data where each observation within a group is a draw from a mixture model and where it is desirable to share mixture components between groups. We assume that the number of mixture components is unknown a priori and is to be inferred from the data. In this setting it is natural to consider sets of Dirichlet processes, one for each group, where the well-known clustering property of the Dirichlet process provides a nonparametric prior for the number of mixture components within each group. Given our desire to tie the mixture models in the various groups, we consider a hierarchical model, specifically one in which the base measure for the child Dirichlet processes is itself distributed according to a Dirichlet process. Such a base measure being discrete, the child Dirichlet processes necessarily share atoms. Thus, as desired, the mixture models in the different groups necessarily share mixture components. We discuss representations of hierarchical Dirichlet processes in terms of a stick-breaking process, and a generalization of the Chinese restaurant process that we refer to as the “Chinese restaurant franchise.” We present Markov chain Monte Carlo algorithms for posterior inference in hierarchical Dirichlet process mixtures and describe applications to problems in information retrieval and text modeling.},
  Doi                      = {10.1198/016214506000000302},
  Eprint                   = {http://dx.doi.org/10.1198/016214506000000302},
  Owner                    = {iurteaga},
  Timestamp                = {2016.11.15},
  Url                      = {http://dx.doi.org/10.1198/016214506000000302}
}

@InProceedings{ip-Teh2008,
  Title                    = {{Collapsed Variational Inference for HDP}},
  Author                   = {Yee Whye Teh and Kenichi Kurihara and Max Welling},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2008},
  Volume                   = {20},

  Keywords                 = {HDP, variational},
  Owner                    = {iurteaga},
  Timestamp                = {2017.04.20},
  Url                      = {https://papers.nips.cc/paper/3342-collapsed-variational-inference-for-hdp.pdf}
}

@InProceedings{ip-Teh2007,
  Title                    = {{A Collapsed Variational Bayesian Inference Algorithm for Latent Dirichlet Allocation}},
  Author                   = {Yee Whye Teh and David Newman and Max Welling},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2007},
  Volume                   = {19},

  Owner                    = {iurteaga},
  Timestamp                = {2017.04.20},
  Url                      = {https://papers.nips.cc/paper/3113-a-collapsed-variational-bayesian-inference-algorithm-for-latent-dirichlet-allocation.pdf}
}

@Article{j-Thompson1935,
  Title                    = {{On the Theory of Apportionment}},
  Author                   = {William R. Thompson},
  Journal                  = {American Journal of Mathematics},
  Year                     = {1935},
  Number                   = {2},
  Pages                    = {450-456},
  Volume                   = {57},

  File                     = {:home/iurteaga/Columbia/academic/bib/causalModelingAndBandits/onTheoryOfApportionment_Thompson1935.pdf:PDF},
  ISSN                     = {00029327, 10806377},
  Owner                    = {iurteaga},
  Publisher                = {Johns Hopkins University Press},
  Timestamp                = {2016.09.20},
  Url                      = {http://www.jstor.org/stable/2371219}
}

@Article{j-Thompson1933,
  Title                    = {{On the Likelihood that One Unknown Probability Exceeds Another in View of the Evidence of Two Samples}},
  Author                   = {William R. Thompson},
  Journal                  = {Biometrika},
  Year                     = {1933},
  Number                   = {3/4},
  Pages                    = {285-294},
  Volume                   = {25},

  File                     = {Thompson's original paper:home/iurteaga/Columbia/academic/bib/causalModelingAndBandits/onLikelihoodOneProbExceedsAnotherEvidenceTwoSamples_Thompson1933.pdf:PDF},
  ISSN                     = {00063444},
  Owner                    = {iurteaga},
  Publisher                = {[Oxford University Press, Biometrika Trust]},
  Timestamp                = {2016.09.19},
  Url                      = {http://www.jstor.org/stable/2332286}
}

@Article{j-Wang2012,
  Title                    = {{Continuous time dynamic topic models}},
  Author                   = {Chong Wang and Dvid Blei and Dvaid Heckerman},
  Journal                  = {arXiv preprint arXiv:1206.3298},
  Year                     = {2012},

  Abstract                 = {In this paper, we develop the continuous time dynamic topic model (cDTM). The cDTM is a dynamic topic model that uses Brownian motion to model the latent topics through a sequential collection of documents, where a "topic" is a pattern of word use that we expect to evolve over the course of the collection. We derive an efficient variational approximate inference algorithm that takes advantage of the sparsity of observations in text, a property that lets us easily handle many time points. In contrast to the cDTM, the original discrete-time dynamic topic model (dDTM) requires that time be discretized. Moreover, the complexity of variational inference for the dDTM grows quickly as time granularity increases, a drawback which limits fine-grained discretization. We demonstrate the cDTM on two news corpora, reporting both predictive perplexity and the novel task of time stamp prediction.},
  Owner                    = {iurteaga},
  Timestamp                = {2016.11.15},
  Url                      = {https://arxiv.org/abs/1206.3298}
}

@InProceedings{ip-Wang2009,
  Title                    = {{Markov Topic Models}},
  Author                   = {Chong Wang and Bo Thiesson and Chris Meek and David Blei},
  Booktitle                = {D. van Dyk and M. Welling (Eds.), Proceedings of The Twelfth International Conference on Artificial Intelligence and Statistics (AISTATS) 2009, JMLR: W\&CP 5},
  Year                     = {2009},
  Month                    = {April},
  Pages                    = {583-590},
  Publisher                = {Journal of Machine Learning Research},

  Abstract                 = {We develop Markov topic models (MTMs), a novel family of generative probabilistic models that can learn topics simultaneously from multiple corpora, such as papers from different conferences. We apply Gaussian (Markov) random fields to model the correlations of different corpora. MTMs capture both the internal topic structure within each corpus and the relationships between topics across the corpora. We derive an efficient estimation procedure with variational expectation-maximization. We study the performance of our models on a corpus of abstracts from six different computer science conferences. Our analysis reveals qualitative discoveries that are not possible with traditional topic models, and improved quantitative performance over the state of the art.},
  Owner                    = {iurteaga},
  Timestamp                = {2016.11.15},
  Url                      = {https://www.microsoft.com/en-us/research/publication/markov-topic-models/}
}

@InProceedings{ip-Wang2006,
  Title                    = {{Topics over Time: A non-Markov Continuous-time Model of Topical Trends}},
  Author                   = {Xuerui Wang and Andrew McCallum},
  Booktitle                = {Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  Year                     = {2006},

  Address                  = {New York, NY, USA},
  Pages                    = {424--433},
  Publisher                = {ACM},
  Series                   = {KDD '06},

  Acmid                    = {1150450},
  Doi                      = {10.1145/1150402.1150450},
  ISBN                     = {1-59593-339-5},
  Keywords                 = {graphical models, temporal analysis, topic modeling},
  Location                 = {Philadelphia, PA, USA},
  Numpages                 = {10},
  Owner                    = {iurteaga},
  Timestamp                = {2016.11.15},
  Url                      = {http://doi.acm.org/10.1145/1150402.1150450}
}

@comment{jabref-meta: databaseType:bibtex;}

